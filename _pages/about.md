---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I'm a PhD student in Computer Science at the University of Washington. I work in the [Mobile Intelligence Lab](http://netlab.cs.washington.edu) advised by [Prof. Shyam Gollakota](https://homes.cs.washington.edu/~gshyam/) and [Prof. Michael Taylor](http://michaeltaylor.org/). I'm also working at [Meta AI](https://ai.meta.com/) as a visiting researcher. I'm interested in Speech/Audio Language Modeling, Conversational AI and Human-Computer Interaction. I got my Bachelor's degree at the Indian Institute of Technology Roorkee and my Master's degree at the University of Washington.

<p style="text-align: center; margin: 20px 0; font-size: 0.9em;">
✨ Open to full-time research positions starting Spring/Summer 2025. ✨
</p>

## News
<style>
.boxhead a {
    color: #FFFFFF;
    text-decoration: none;
}
</style>

<small>
Sep 20, 2024 -- [SyncLLM](https://syncllm.cs.washington.edu/) accepted to EMNLP Main 2024!  
</small>
<small>
May 23, 2024 -- _Look Once to Hear_ covered by [MIT Tech Review](https://www.technologyreview.com/2024/05/23/1092832/noise-canceling-headphones-use-ai-to-let-a-single-voice-through/)! P.S: Also in [U.S.News & World Report](https://www.usnews.com/news/health-news/articles/2024-05-28/ai-headphones-let-listeners-hear-just-one-voice-in-a-crowd), [GeekWire](https://www.geekwire.com/2024/look-and-listen-ai-headphones-cancel-background-noise-and-focus-on-one-speaker-after-a-glance/) and [UW News](https://www.washington.edu/news/2024/05/23/ai-headphones-noise-cancelling-target-speech-hearing/).  
</small>
<small>
May 11, 2024 -- _Look Once to Hear_ received best paper honorable mention award at CHI 2024!  
</small>
<small>
Nov 9, 2023  -- _Semantic Hearing_ covered by [MIT Tech Review](https://www.technologyreview.com/2023/11/09/1083145/noise-canceling-headphones-could-let-you-pick-and-choose-the-sounds-you-want-to-hear/) and [UW News](https://www.washington.edu/news/2023/11/09/ai-noise-canceling-headphones/)!
</small>

## Recent publications
<style>
.boxhead a {
    color: #FFFFFF;
    text-decoration: none;
}
</style>

__Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents__  
<small>
Bandhav Veluri, Benjamin N Peloquin, Bokai Yu, Hongyu Gong, Shyamnath Gollakota  
_EMNLP Main 2024_    
<a href="https://arxiv.org/abs/2409.15594" target="_blank">
  <img src="https://img.shields.io/badge/Paper-grey" alt="Paper">
</a> 
<a href="https://syncllm.cs.washington.edu/" target="_blank">
  <img src="https://img.shields.io/badge/Website-grey" alt="Website">
</a> 
</small>
<video controls poster="assets/syncllm_thumb.png" width=320 style="margin-bottom: 20px;">
  <source src="https://syncllm.cs.washington.edu/SyncLLM.mp4" type="video/mp4">
</video>


__IRIS: Wireless Ring for Vision-based Smart Home Interaction__  
<small>
Maruchi Kim\*, Antonio Glenn\*, Bandhav Veluri\*, Yunseo Lee, Eyoel Gebre, Aditya Bagaria, Shwetak Patel, Shyamnath Gollakota  
_ACM UIST 2024_  
<a href="https://arxiv.org/abs/2407.18141" target="_blank">
  <img src="https://img.shields.io/badge/Paper-grey" alt="Paper">
</a> 
</small>
<div class="videoWrapper" style="width: 320px; float: left;" >
  <iframe width="560" height="315" src="https://www.youtube.com/embed/OGPSiZtvnaI?si=RCZuiEop675Ag4cC" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

<br style="clear: both;">



__Look Once to Hear: Target Speech Hearing with Noisy Examples__  
<small>
Bandhav Veluri\*, Malek Itani\*, Tuochao Chen, Takuya Yoshioka, Shyamnath Gollakota  
_ACM CHI 2024_ &#127942; Best paper honorable mention &#127942;  
<a href="https://arxiv.org/abs/2405.06289" target="_blank">
  <img src="https://img.shields.io/badge/Paper-grey" alt="Paper">
</a> 
<a href="https://tsh.cs.washington.edu/" target="_blank">
  <img src="https://img.shields.io/badge/Website-grey" alt="Website">
</a> 
<a href="https://github.com/vb000/LookOnceToHear" target="_blank">
  <img src="https://img.shields.io/github/stars/vb000/LookOnceToHear?style=social&label=Code" alt="GitHub">
</a>  
 </small>
<div class="videoWrapper" style="width: 320px; float: left;" >
    <iframe width="560" height="315" src="https://www.youtube.com/embed/V-XCfnjfQmM?si=uWQg6hBQaUMnAcjW" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</div>

<br style="clear: both;">

__SeamlessExpressiveLM: Speech Language Model for Expressive Speech-to-Speech Translation with Chain-of-Thought__  
<small>
Hongyu Gong, Bandhav Veluri  
_Arxiv 2024_  
<a href="https://arxiv.org/abs/2405.20410" target="_blank">
  <img src="https://img.shields.io/badge/Paper-grey" alt="Paper">
</a>  
</small>

__Semantic Hearing: Programming Acoustic Scenes with Binaural Hearables__  
<small>
Bandhav Veluri\*, Malek Itani\*, Justin Chan, Takuya Yoshioka, Shyamnath Gollakota  
_ACM UIST 2023_  
<a href="https://arxiv.org/abs/2311.00320" target="_blank">
  <img src="https://img.shields.io/badge/Paper-grey" alt="Paper">
</a> 
<a href="https://semantichearing.cs.washington.edu/" target="_blank">
  <img src="https://img.shields.io/badge/Website-grey" alt="Website">
</a> 
<a href="https://github.com/vb000/SemanticHearing" target="_blank">
  <img src="https://img.shields.io/github/stars/vb000/SemanticHearing?style=social&label=Code" alt="GitHub">
</a>  
</small>
<div class="videoWrapper" style="width: 320px; float: left;" >
    <iframe width="560" height="315" src="https://www.youtube.com/embed/xx3qocTmAK8?si=mEtL7YOu6bbJ0a5v" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</div>  

<br style="clear: both;">

__Real-Time Target Sound Extraction__  
<small>
Bandhav Veluri, Justin Chan, Malek Itani, Tuochao Chen, Takuya Yoshioka, Shyamnath Gollakota  
_IEEE ICASSP 2023_    
<a href="https://arxiv.org/abs/2211.02250" target="_blank">
  <img src="https://img.shields.io/badge/Paper-grey" alt="Paper">
</a> 
<a href="https://waveformer.cs.washington.edu/" target="_blank">
  <img src="https://img.shields.io/badge/Website-grey" alt="Website">
</a> 
<a href="https://github.com/vb000/Waveformer" target="_blank">
  <img src="https://img.shields.io/github/stars/vb000/Waveformer?style=social&label=Code" alt="GitHub">
</a>  
</small>
<video controls src="https://targetsound.cs.washington.edu/files/Gradio-Demo.mp4" width=320 height=180></video>

__NeuriCam: Video Super Resolution and Colorization Using Key Frames__  
<small>
Bandhav Veluri, Ali Saffari, Collin Pernu, Joshua Smith, Michael Taylor, Shyamnath Gollakota  
_MobiCom 2023_  
<a href="https://arxiv.org/abs/2207.12496" target="_blank">
  <img src="https://img.shields.io/badge/Paper-grey" alt="Paper">
</a> 
<a href="https://waveformer.cs.washington.edu/" target="_blank">
  <img src="https://img.shields.io/badge/Website-grey" alt="Website">
</a> 
<a href="https://github.com/vb000/NeuriCam" target="_blank">
  <img src="https://img.shields.io/github/stars/vb000/NeuriCam?style=social&label=Code" alt="GitHub">
</a>  
</small>
<video controls src="https://github.com/vb000/NeuriCam/assets/16723254/d3d2fc4a-2cfa-4f72-918e-c62379569d91" width=320 height=180></video>

<small>(\*Co-primary authors)</small>
